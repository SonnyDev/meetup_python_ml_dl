{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SonnyDev/llm-apps-langchain/blob/main/Embeddings_et_VectorDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "628b4463",
      "metadata": {
        "id": "628b4463"
      },
      "source": [
        "### 1. Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca33901",
      "metadata": {
        "id": "6ca33901"
      },
      "source": [
        "Les embeddings offrent des représentations vectorielles denses des mots\n",
        "et capturent les caractéristiques sémantiques de mots. Ils permettent la mesure de la similarité sémantique entre les mots.\n",
        "Il existe de nombreux fournisseurs de modèles d’embeddings (OpenAI, Cohere, Hugging Face, etc.) La classe Embeddings de LangChain est conçue pour fournir une interface standard pour tous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1a55d32",
      "metadata": {
        "id": "a1a55d32"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv()) # read local .env file\n",
        "openai.api_key = os.environ['OPENAI_API_KEY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce2b84c",
      "metadata": {
        "id": "5ce2b84c",
        "outputId": "ade53e65-e1bb-47f4-87cc-2a5f58de1b30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 1536)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_community.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings()\n",
        "\n",
        "embeddings = embeddings_model.embed_documents(\n",
        "    [\n",
        "        \"Hi there!\",\n",
        "        \"Oh, hello!\",\n",
        "        \"What's your name?\",\n",
        "        \"My friends call me World\",\n",
        "        \"Hello World!\"\n",
        "    ]\n",
        ")\n",
        "len(embeddings), len(embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45d9bb19",
      "metadata": {
        "id": "45d9bb19",
        "outputId": "b6ab0a64-a434-4635-b79c-7d4023fd32dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.004510450978244393,\n",
              " -0.01431200798337721,\n",
              " 0.00197642011460647,\n",
              " -0.015290924838637436,\n",
              " -0.02646792231226287]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings[1][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1172e018",
      "metadata": {
        "id": "1172e018",
        "outputId": "5e84bae8-9efb-4f4f-d325-a68777e6c736"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(58, 1536)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Embed document\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "loader = TextLoader(\"./langchain.txt\", encoding=\"utf-8\")\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "docs\n",
        "\n",
        "# Transform documents\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    length_function=len,\n",
        "    add_start_index=True,\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(docs)\n",
        "\n",
        "\n",
        "for doc in texts:\n",
        "    embedding = embeddings_model.embed_documents(doc.page_content)\n",
        "    embeddings.append(embedding)\n",
        "\n",
        "len(embeddings), len(embeddings[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61c66f1",
      "metadata": {
        "id": "c61c66f1",
        "outputId": "9f0b70bf-0c30-4b34-9147-6d2fa8e9c233"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.020262643931117454,\n",
              " -0.006984279861728337,\n",
              " -0.022630838723440946,\n",
              " -0.02634143617913019,\n",
              " -0.03697932214749123]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings[0][:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c9b8617",
      "metadata": {
        "id": "4c9b8617",
        "outputId": "00d4a163-b4c3-449b-9cea-31fbaf27a8e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0.004442663852323625,\n",
              " -0.016318678663383088,\n",
              " -0.010234509710864969,\n",
              " -0.01468681042451571,\n",
              " -0.013427573699114638]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Embed query\n",
        "\n",
        "embedded_query = embeddings_model.embed_query(\"Qu'est-ce qu'une chaine ?\")\n",
        "embedded_query[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03ef7f43",
      "metadata": {
        "id": "03ef7f43"
      },
      "source": [
        "### 2. Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d2a8486",
      "metadata": {
        "id": "4d2a8486"
      },
      "outputs": [],
      "source": [
        "# ChromaDB (!pip install chromadb)\n",
        "\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af22826a",
      "metadata": {
        "id": "af22826a",
        "outputId": "58b299a0-f614-4af7-a5a9-ab64c56b4c2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content=\"être utilisés pour générer du texte, répondre à des questions, ou effectuer d'autres tâches liées au langage naturel.\", metadata={'source': './langchain.txt', 'start_index': 196})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texts[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70ee523c",
      "metadata": {
        "id": "70ee523c"
      },
      "outputs": [],
      "source": [
        "chroma_db = Chroma.from_documents(\n",
        "    documents=texts,\n",
        "    embedding=embeddings_model,\n",
        "    persist_directory=\"vector_db\",\n",
        "    collection_name=\"lc_chroma_db\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4369b172",
      "metadata": {
        "id": "4369b172"
      },
      "outputs": [],
      "source": [
        "# Similarity search\n",
        "\n",
        "query = \"Qu'est-ce qu'un agent ?\"\n",
        "\n",
        "similar_docs = chroma_db.similarity_search(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f04193",
      "metadata": {
        "id": "38f04193",
        "outputId": "ba8258f4-0269-41af-cdd6-dfbae972eb2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content=\"SQL à l'aide d'agents.\", metadata={'source': './langchain.txt', 'start_index': 3730}),\n",
              " Document(page_content=\"SQL à l'aide d'agents.\", metadata={'source': './langchain.txt', 'start_index': 0, 'tag': 'agents'}),\n",
              " Document(page_content=\"• Agents : Les agents permettent d'utiliser des modèles de langage comme moteur de raisonnement en prenant des décisions et en effectuant des actions en fonction des instructions et des données\", metadata={'source': './langchain.txt', 'start_index': 1232}),\n",
              " Document(page_content=\"• Agents : Les agents permettent d'utiliser des modèles de langage comme moteur de raisonnement en prenant des décisions et en effectuant des actions en fonction des instructions et des données\", metadata={'source': './langchain.txt', 'start_index': 1232})]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "similar_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35bc98d7",
      "metadata": {
        "id": "35bc98d7",
        "outputId": "0e2698e7-d0ec-48ef-f53f-d232d73f2b91"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': ['0d6d65f5-a35b-11ee-9387-c17a6171887f',\n",
              "  '0d6d65f6-a35b-11ee-b467-c17a6171887f',\n",
              "  '0d6d65f7-a35b-11ee-b3a7-c17a6171887f',\n",
              "  '0d6d65f8-a35b-11ee-a719-c17a6171887f',\n",
              "  '0d6d65f9-a35b-11ee-8aa7-c17a6171887f',\n",
              "  '0d6d65fa-a35b-11ee-b8c6-c17a6171887f',\n",
              "  '0d6d65fb-a35b-11ee-bbb9-c17a6171887f',\n",
              "  '0d6d65fc-a35b-11ee-bb21-c17a6171887f',\n",
              "  '0d6d65fd-a35b-11ee-b9a5-c17a6171887f',\n",
              "  '0d6d65fe-a35b-11ee-a5c6-c17a6171887f',\n",
              "  '0d6d65ff-a35b-11ee-9729-c17a6171887f',\n",
              "  '0d6d6600-a35b-11ee-be83-c17a6171887f',\n",
              "  '0d6d6601-a35b-11ee-aa63-c17a6171887f',\n",
              "  '0d6d6602-a35b-11ee-b8d6-c17a6171887f',\n",
              "  '0d6d6603-a35b-11ee-b32d-c17a6171887f',\n",
              "  '0d6d6604-a35b-11ee-ac63-c17a6171887f',\n",
              "  '0d6d6605-a35b-11ee-809c-c17a6171887f',\n",
              "  '0d6d6606-a35b-11ee-abd2-c17a6171887f',\n",
              "  '0d6d6607-a35b-11ee-a194-c17a6171887f',\n",
              "  '0d6d6608-a35b-11ee-b361-c17a6171887f',\n",
              "  '0d6d6609-a35b-11ee-82c4-c17a6171887f',\n",
              "  '0d6d660a-a35b-11ee-bd39-c17a6171887f',\n",
              "  '0d6d660b-a35b-11ee-8bb4-c17a6171887f',\n",
              "  '0d6d660c-a35b-11ee-99e7-c17a6171887f',\n",
              "  '0d6d660d-a35b-11ee-8f2e-c17a6171887f',\n",
              "  '0d6d660e-a35b-11ee-9c62-c17a6171887f',\n",
              "  '0d6d660f-a35b-11ee-b57d-c17a6171887f',\n",
              "  '0d6d6610-a35b-11ee-9245-c17a6171887f',\n",
              "  '0d6d6611-a35b-11ee-9383-c17a6171887f',\n",
              "  '0d6d6612-a35b-11ee-b3a7-c17a6171887f',\n",
              "  '0d6d6613-a35b-11ee-aeab-c17a6171887f',\n",
              "  '0d6d6614-a35b-11ee-b512-c17a6171887f',\n",
              "  '0d6d6615-a35b-11ee-bbb6-c17a6171887f',\n",
              "  '0d6d6616-a35b-11ee-b4a9-c17a6171887f',\n",
              "  '0d6d6617-a35b-11ee-b9d1-c17a6171887f',\n",
              "  '0d6d6618-a35b-11ee-ab87-c17a6171887f',\n",
              "  '0d6d6619-a35b-11ee-adfd-c17a6171887f',\n",
              "  '0d6d661a-a35b-11ee-933b-c17a6171887f',\n",
              "  '0d6d661b-a35b-11ee-a5fd-c17a6171887f',\n",
              "  '0d6d661c-a35b-11ee-b88b-c17a6171887f',\n",
              "  '0d6d661d-a35b-11ee-bb7e-c17a6171887f',\n",
              "  '0d6d661e-a35b-11ee-84bd-c17a6171887f',\n",
              "  '0d6d661f-a35b-11ee-b088-c17a6171887f',\n",
              "  '0d6d6620-a35b-11ee-bd9b-c17a6171887f',\n",
              "  '0d6d6621-a35b-11ee-8e60-c17a6171887f',\n",
              "  '0d6d6622-a35b-11ee-96a2-c17a6171887f',\n",
              "  '0d6d6623-a35b-11ee-852b-c17a6171887f',\n",
              "  '0d6d6624-a35b-11ee-b1bd-c17a6171887f',\n",
              "  '0d6d6625-a35b-11ee-a8fb-c17a6171887f',\n",
              "  '0d6d6626-a35b-11ee-a2dc-c17a6171887f',\n",
              "  '0d6d6627-a35b-11ee-9ec4-c17a6171887f',\n",
              "  '0d6d6628-a35b-11ee-a25f-c17a6171887f',\n",
              "  '0d6d6629-a35b-11ee-9ef0-c17a6171887f',\n",
              "  '37ebbc89-a340-11ee-b46f-c17a6171887f',\n",
              "  '37ebbc8a-a340-11ee-9fe3-c17a6171887f',\n",
              "  '37ebf250-a340-11ee-9fcf-c17a6171887f',\n",
              "  '37ebf251-a340-11ee-8350-c17a6171887f',\n",
              "  '37ebf252-a340-11ee-97ba-c17a6171887f',\n",
              "  '37ebf253-a340-11ee-bed5-c17a6171887f',\n",
              "  '37ebf254-a340-11ee-8add-c17a6171887f',\n",
              "  '37ebf255-a340-11ee-b35a-c17a6171887f',\n",
              "  '37ebf256-a340-11ee-8ade-c17a6171887f',\n",
              "  '37ebf257-a340-11ee-ae1d-c17a6171887f',\n",
              "  '37ebf258-a340-11ee-a297-c17a6171887f',\n",
              "  '37ebf259-a340-11ee-b2ea-c17a6171887f',\n",
              "  '37ebf25a-a340-11ee-a87f-c17a6171887f',\n",
              "  '37ebf25b-a340-11ee-9457-c17a6171887f',\n",
              "  '37ebf25c-a340-11ee-935a-c17a6171887f',\n",
              "  '37ebf25d-a340-11ee-acd9-c17a6171887f',\n",
              "  '37ebf25e-a340-11ee-b266-c17a6171887f',\n",
              "  '37ebf25f-a340-11ee-a959-c17a6171887f',\n",
              "  '37ebf260-a340-11ee-8e6c-c17a6171887f',\n",
              "  '37ebf261-a340-11ee-b7d2-c17a6171887f',\n",
              "  '37ebf262-a340-11ee-973c-c17a6171887f',\n",
              "  '37ebf263-a340-11ee-85e1-c17a6171887f',\n",
              "  '37ebf264-a340-11ee-a3ed-c17a6171887f',\n",
              "  '37ebf265-a340-11ee-b0b5-c17a6171887f',\n",
              "  '37ebf266-a340-11ee-ac52-c17a6171887f',\n",
              "  '37ebf267-a340-11ee-9286-c17a6171887f',\n",
              "  '37ebf268-a340-11ee-941e-c17a6171887f',\n",
              "  '37ebf269-a340-11ee-aa8e-c17a6171887f',\n",
              "  '37ebf26a-a340-11ee-841c-c17a6171887f',\n",
              "  '37ebf26b-a340-11ee-907a-c17a6171887f',\n",
              "  '37ebf26c-a340-11ee-a4e5-c17a6171887f',\n",
              "  '37ebf26d-a340-11ee-9119-c17a6171887f',\n",
              "  '37ebf26e-a340-11ee-a764-c17a6171887f',\n",
              "  '37ebf26f-a340-11ee-a03e-c17a6171887f',\n",
              "  '37ebf270-a340-11ee-9bd4-c17a6171887f',\n",
              "  '37ebf271-a340-11ee-90c1-c17a6171887f',\n",
              "  '37ebf272-a340-11ee-bdc1-c17a6171887f',\n",
              "  '37ebf273-a340-11ee-ba02-c17a6171887f',\n",
              "  '37ebf274-a340-11ee-bf84-c17a6171887f',\n",
              "  '37ebf275-a340-11ee-9521-c17a6171887f',\n",
              "  '37ebf276-a340-11ee-955d-c17a6171887f',\n",
              "  '37ebf277-a340-11ee-8bad-c17a6171887f',\n",
              "  '37ebf278-a340-11ee-8042-c17a6171887f',\n",
              "  '37ebf279-a340-11ee-a2ad-c17a6171887f',\n",
              "  '37ebf27a-a340-11ee-8e0e-c17a6171887f',\n",
              "  '37ebf27b-a340-11ee-8a10-c17a6171887f',\n",
              "  '37ebf27c-a340-11ee-9c24-c17a6171887f',\n",
              "  '37ebf27d-a340-11ee-bfd1-c17a6171887f',\n",
              "  '37ebf27e-a340-11ee-b5e4-c17a6171887f',\n",
              "  '37ebf27f-a340-11ee-922b-c17a6171887f',\n",
              "  '37ebf280-a340-11ee-805c-c17a6171887f',\n",
              "  '37ebf281-a340-11ee-a347-c17a6171887f',\n",
              "  '37ebf282-a340-11ee-abeb-c17a6171887f',\n",
              "  '37ebf283-a340-11ee-8599-c17a6171887f',\n",
              "  '37ebf284-a340-11ee-999f-c17a6171887f',\n",
              "  '37ebf285-a340-11ee-86da-c17a6171887f',\n",
              "  '37ebf286-a340-11ee-be2d-c17a6171887f',\n",
              "  '37ebf287-a340-11ee-b676-c17a6171887f',\n",
              "  '37ebf288-a340-11ee-8d08-c17a6171887f',\n",
              "  '37ebf289-a340-11ee-9908-c17a6171887f',\n",
              "  '37ebf28a-a340-11ee-ba2e-c17a6171887f',\n",
              "  '37ebf28b-a340-11ee-8764-c17a6171887f',\n",
              "  '37ebf28c-a340-11ee-834f-c17a6171887f',\n",
              "  '37ebf28d-a340-11ee-b820-c17a6171887f',\n",
              "  '37ebf28e-a340-11ee-9bfc-c17a6171887f',\n",
              "  '37ebf28f-a340-11ee-9169-c17a6171887f',\n",
              "  '37ebf290-a340-11ee-8029-c17a6171887f',\n",
              "  '37ebf291-a340-11ee-a8ac-c17a6171887f',\n",
              "  '37ebf292-a340-11ee-9209-c17a6171887f',\n",
              "  '37ebf293-a340-11ee-b244-c17a6171887f',\n",
              "  '37ebf294-a340-11ee-96fa-c17a6171887f',\n",
              "  '37ebf295-a340-11ee-92f9-c17a6171887f',\n",
              "  '37ebf296-a340-11ee-915b-c17a6171887f',\n",
              "  '37ebf297-a340-11ee-b74d-c17a6171887f',\n",
              "  '37ebf298-a340-11ee-bcc9-c17a6171887f',\n",
              "  '37ec18d3-a340-11ee-9482-c17a6171887f',\n",
              "  '37ec18d4-a340-11ee-a766-c17a6171887f',\n",
              "  '37ec18d5-a340-11ee-83e6-c17a6171887f',\n",
              "  '37ec18d6-a340-11ee-9f56-c17a6171887f',\n",
              "  '37ec18d7-a340-11ee-b37d-c17a6171887f',\n",
              "  '37ec18d8-a340-11ee-9705-c17a6171887f',\n",
              "  '37ec18d9-a340-11ee-8a6d-c17a6171887f',\n",
              "  '37ec18da-a340-11ee-b40a-c17a6171887f',\n",
              "  '37ec18db-a340-11ee-8e7e-c17a6171887f',\n",
              "  '37ec18dc-a340-11ee-af25-c17a6171887f',\n",
              "  '37ec18dd-a340-11ee-be55-c17a6171887f',\n",
              "  '37ec18de-a340-11ee-91f2-c17a6171887f',\n",
              "  '37ec18df-a340-11ee-aede-c17a6171887f',\n",
              "  'f01bbb2b-a340-11ee-a777-c17a6171887f',\n",
              "  'f01bbb2c-a340-11ee-b9cf-c17a6171887f',\n",
              "  'f01bbb2d-a340-11ee-9ac2-c17a6171887f',\n",
              "  'f01bbb2e-a340-11ee-ba1d-c17a6171887f',\n",
              "  'f01bbb2f-a340-11ee-b065-c17a6171887f',\n",
              "  'f01bbb30-a340-11ee-925f-c17a6171887f',\n",
              "  'f01bbb31-a340-11ee-946d-c17a6171887f',\n",
              "  'f01bbb32-a340-11ee-8e92-c17a6171887f',\n",
              "  'f01bbb33-a340-11ee-9099-c17a6171887f',\n",
              "  'f01bbb34-a340-11ee-bb80-c17a6171887f'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [{'source': './langchain.txt', 'start_index': 0},\n",
              "  {'source': './langchain.txt', 'start_index': 12},\n",
              "  {'source': './langchain.txt', 'start_index': 196},\n",
              "  {'source': './langchain.txt', 'start_index': 314},\n",
              "  {'source': './langchain.txt', 'start_index': 494},\n",
              "  {'source': './langchain.txt', 'start_index': 571},\n",
              "  {'source': './langchain.txt', 'start_index': 755},\n",
              "  {'source': './langchain.txt', 'start_index': 815},\n",
              "  {'source': './langchain.txt', 'start_index': 1005},\n",
              "  {'source': './langchain.txt', 'start_index': 1191},\n",
              "  {'source': './langchain.txt', 'start_index': 1232},\n",
              "  {'source': './langchain.txt', 'start_index': 1411},\n",
              "  {'source': './langchain.txt', 'start_index': 1527},\n",
              "  {'source': './langchain.txt', 'start_index': 1549},\n",
              "  {'source': './langchain.txt', 'start_index': 1718},\n",
              "  {'source': './langchain.txt', 'start_index': 1868},\n",
              "  {'source': './langchain.txt', 'start_index': 2050},\n",
              "  {'source': './langchain.txt', 'start_index': 2084},\n",
              "  {'source': './langchain.txt', 'start_index': 2258},\n",
              "  {'source': './langchain.txt', 'start_index': 2294},\n",
              "  {'source': './langchain.txt', 'start_index': 2480},\n",
              "  {'source': './langchain.txt', 'start_index': 2563},\n",
              "  {'source': './langchain.txt', 'start_index': 2740},\n",
              "  {'source': './langchain.txt', 'start_index': 2779},\n",
              "  {'source': './langchain.txt', 'start_index': 2963},\n",
              "  {'source': './langchain.txt', 'start_index': 3010},\n",
              "  {'source': './langchain.txt', 'start_index': 3182},\n",
              "  {'source': './langchain.txt', 'start_index': 3239},\n",
              "  {'source': './langchain.txt', 'start_index': 3418},\n",
              "  {'source': './langchain.txt', 'start_index': 3466},\n",
              "  {'source': './langchain.txt', 'start_index': 3489},\n",
              "  {'source': './langchain.txt', 'start_index': 3672},\n",
              "  {'source': './langchain.txt', 'start_index': 3753},\n",
              "  {'source': './langchain.txt', 'start_index': 3939},\n",
              "  {'source': './langchain.txt', 'start_index': 4004},\n",
              "  {'source': './langchain.txt', 'start_index': 4200},\n",
              "  {'source': './langchain.txt', 'start_index': 4374},\n",
              "  {'source': './langchain.txt', 'start_index': 4459},\n",
              "  {'source': './langchain.txt', 'start_index': 4493},\n",
              "  {'source': './langchain.txt', 'start_index': 4671},\n",
              "  {'source': './langchain.txt', 'start_index': 4700},\n",
              "  {'source': './langchain.txt', 'start_index': 4881},\n",
              "  {'source': './langchain.txt', 'start_index': 4953},\n",
              "  {'source': './langchain.txt', 'start_index': 5141},\n",
              "  {'source': './langchain.txt', 'start_index': 5320},\n",
              "  {'source': './langchain.txt', 'start_index': 5352},\n",
              "  {'source': './langchain.txt', 'start_index': 5528},\n",
              "  {'source': './langchain.txt', 'start_index': 5585},\n",
              "  {'source': './langchain.txt', 'start_index': 5761},\n",
              "  {'source': './langchain.txt', 'start_index': 5807},\n",
              "  {'source': './langchain.txt', 'start_index': 5988},\n",
              "  {'source': './langchain.txt', 'start_index': 6019},\n",
              "  {'source': './langchain.txt', 'start_index': 6197},\n",
              "  {'source': './langchain.txt', 'start_index': 0, 'tag': 'agents'},\n",
              "  {'source': './langchain.txt', 'start_index': 12},\n",
              "  {'source': './langchain.txt', 'start_index': 100},\n",
              "  {'source': './langchain.txt', 'start_index': 176},\n",
              "  {'source': './langchain.txt', 'start_index': 259},\n",
              "  {'source': './langchain.txt', 'start_index': 314},\n",
              "  {'source': './langchain.txt', 'start_index': 395},\n",
              "  {'source': './langchain.txt', 'start_index': 479},\n",
              "  {'source': './langchain.txt', 'start_index': 571},\n",
              "  {'source': './langchain.txt', 'start_index': 652},\n",
              "  {'source': './langchain.txt', 'start_index': 728},\n",
              "  {'source': './langchain.txt', 'start_index': 815},\n",
              "  {'source': './langchain.txt', 'start_index': 890},\n",
              "  {'source': './langchain.txt', 'start_index': 978},\n",
              "  {'source': './langchain.txt', 'start_index': 1005},\n",
              "  {'source': './langchain.txt', 'start_index': 1082},\n",
              "  {'source': './langchain.txt', 'start_index': 1165},\n",
              "  {'source': './langchain.txt', 'start_index': 1232},\n",
              "  {'source': './langchain.txt', 'start_index': 1312},\n",
              "  {'source': './langchain.txt', 'start_index': 1394},\n",
              "  {'source': './langchain.txt', 'start_index': 1473},\n",
              "  {'source': './langchain.txt', 'start_index': 1527},\n",
              "  {'source': './langchain.txt', 'start_index': 1549},\n",
              "  {'source': './langchain.txt', 'start_index': 1636},\n",
              "  {'source': './langchain.txt', 'start_index': 1718},\n",
              "  {'source': './langchain.txt', 'start_index': 1798},\n",
              "  {'source': './langchain.txt', 'start_index': 1868},\n",
              "  {'source': './langchain.txt', 'start_index': 1950},\n",
              "  {'source': './langchain.txt', 'start_index': 2036},\n",
              "  {'source': './langchain.txt', 'start_index': 2084},\n",
              "  {'source': './langchain.txt', 'start_index': 2167},\n",
              "  {'source': './langchain.txt', 'start_index': 2258},\n",
              "  {'source': './langchain.txt', 'start_index': 2294},\n",
              "  {'source': './langchain.txt', 'start_index': 2376},\n",
              "  {'source': './langchain.txt', 'start_index': 2454},\n",
              "  {'source': './langchain.txt', 'start_index': 2539},\n",
              "  {'source': './langchain.txt', 'start_index': 2563},\n",
              "  {'source': './langchain.txt', 'start_index': 2644},\n",
              "  {'source': './langchain.txt', 'start_index': 2725},\n",
              "  {'source': './langchain.txt', 'start_index': 2779},\n",
              "  {'source': './langchain.txt', 'start_index': 2856},\n",
              "  {'source': './langchain.txt', 'start_index': 2935},\n",
              "  {'source': './langchain.txt', 'start_index': 3010},\n",
              "  {'source': './langchain.txt', 'start_index': 3085},\n",
              "  {'source': './langchain.txt', 'start_index': 3169},\n",
              "  {'source': './langchain.txt', 'start_index': 3239},\n",
              "  {'source': './langchain.txt', 'start_index': 3318},\n",
              "  {'source': './langchain.txt', 'start_index': 3405},\n",
              "  {'source': './langchain.txt', 'start_index': 3466},\n",
              "  {'source': './langchain.txt', 'start_index': 3489},\n",
              "  {'source': './langchain.txt', 'start_index': 3569},\n",
              "  {'source': './langchain.txt', 'start_index': 3647},\n",
              "  {'source': './langchain.txt', 'start_index': 3730},\n",
              "  {'source': './langchain.txt', 'start_index': 3753},\n",
              "  {'source': './langchain.txt', 'start_index': 3834},\n",
              "  {'source': './langchain.txt', 'start_index': 3913},\n",
              "  {'source': './langchain.txt', 'start_index': 4004},\n",
              "  {'source': './langchain.txt', 'start_index': 4079},\n",
              "  {'source': './langchain.txt', 'start_index': 4164},\n",
              "  {'source': './langchain.txt', 'start_index': 4200},\n",
              "  {'source': './langchain.txt', 'start_index': 4283},\n",
              "  {'source': './langchain.txt', 'start_index': 4360},\n",
              "  {'source': './langchain.txt', 'start_index': 4459},\n",
              "  {'source': './langchain.txt', 'start_index': 4493},\n",
              "  {'source': './langchain.txt', 'start_index': 4571},\n",
              "  {'source': './langchain.txt', 'start_index': 4656},\n",
              "  {'source': './langchain.txt', 'start_index': 4700},\n",
              "  {'source': './langchain.txt', 'start_index': 4784},\n",
              "  {'source': './langchain.txt', 'start_index': 4868},\n",
              "  {'source': './langchain.txt', 'start_index': 4953},\n",
              "  {'source': './langchain.txt', 'start_index': 5034},\n",
              "  {'source': './langchain.txt', 'start_index': 5108},\n",
              "  {'source': './langchain.txt', 'start_index': 5141},\n",
              "  {'source': './langchain.txt', 'start_index': 5216},\n",
              "  {'source': './langchain.txt', 'start_index': 5293},\n",
              "  {'source': './langchain.txt', 'start_index': 5320},\n",
              "  {'source': './langchain.txt', 'start_index': 5352},\n",
              "  {'source': './langchain.txt', 'start_index': 5435},\n",
              "  {'source': './langchain.txt', 'start_index': 5512},\n",
              "  {'source': './langchain.txt', 'start_index': 5585},\n",
              "  {'source': './langchain.txt', 'start_index': 5659},\n",
              "  {'source': './langchain.txt', 'start_index': 5740},\n",
              "  {'source': './langchain.txt', 'start_index': 5807},\n",
              "  {'source': './langchain.txt', 'start_index': 5883},\n",
              "  {'source': './langchain.txt', 'start_index': 5964},\n",
              "  {'source': './langchain.txt', 'start_index': 6019},\n",
              "  {'source': './langchain.txt', 'start_index': 6095},\n",
              "  {'source': './langchain.txt', 'start_index': 6174},\n",
              "  {'source': './langchain.txt', 'start_index': 0},\n",
              "  {'source': './langchain.txt', 'start_index': 12},\n",
              "  {'source': './langchain.txt', 'start_index': 1005},\n",
              "  {'source': './langchain.txt', 'start_index': 1527},\n",
              "  {'source': './langchain.txt', 'start_index': 1549},\n",
              "  {'source': './langchain.txt', 'start_index': 2294},\n",
              "  {'source': './langchain.txt', 'start_index': 3239},\n",
              "  {'source': './langchain.txt', 'start_index': 3466},\n",
              "  {'source': './langchain.txt', 'start_index': 4459},\n",
              "  {'source': './langchain.txt', 'start_index': 5352}],\n",
              " 'documents': ['1. Modules',\n",
              "  \"• Modèles : Les modèles sont des composants clés de LangChain qui permettent d'utiliser différents types de modèles de langage, tels que GPT-3, BERT, ou encore T5. Ces modèles peuvent être utilisés\",\n",
              "  \"être utilisés pour générer du texte, répondre à des questions, ou effectuer d'autres tâches liées au langage naturel.\",\n",
              "  '• Prompts : Les prompts sont des instructions ou des exemples donnés aux modèles de langage pour les guider dans leur génération de texte. Ils peuvent être utilisés pour spécifier le contexte, poser',\n",
              "  'le contexte, poser des questions ou fournir des indications supplémentaires.',\n",
              "  \"• Mémoire : La mémoire permet de stocker des informations entre les appels d'une chaîne ou d'un agent. Elle peut être utilisée pour conserver des états, des variables ou des résultats intermédiaires\",\n",
              "  \"intermédiaires lors de l'exécution d'une séquence d'appels.\",\n",
              "  \"• Indexes : Les indexes permettent de combiner des modèles de langage avec vos propres données textuelles. Ils facilitent la recherche et l'accès aux informations dans les données indexées.\",\n",
              "  \"• Chaînes : Les chaînes sont des séquences d'appels à des modèles de langage ou à d'autres utilitaires. Elles permettent de créer des flux de travail complexes en enchaînant différentes étapes de\",\n",
              "  'étapes de traitement du langage naturel.',\n",
              "  \"• Agents : Les agents permettent d'utiliser des modèles de langage comme moteur de raisonnement en prenant des décisions et en effectuant des actions en fonction des instructions et des données\",\n",
              "  \"et des données d'entrée. Ils peuvent être utilisés pour créer des assistants virtuels ou des chatbots interactifs.\",\n",
              "  \"2. Cas d'utilisation\",\n",
              "  \"• Assistants personnels : Les applications d'assistants personnels utilisent LangChain pour prendre des actions, se souvenir des interactions et avoir des connaissances sur les données de\",\n",
              "  \"sur les données de l'utilisateur. Ils peuvent répondre aux questions, effectuer des tâches spécifiques et fournir des recommandations personnalisées.\",\n",
              "  '• Réponse aux questions : LangChain peut être utilisé pour répondre aux questions en utilisant des documents spécifiques. Il peut extraire les informations pertinentes des documents et générer des',\n",
              "  'et générer des réponses précises.',\n",
              "  '• Chatbots : Les chatbots utilisent LangChain pour interagir avec les utilisateurs en langage naturel. Ils peuvent comprendre les questions, fournir des réponses pertinentes et mener des',\n",
              "  'et mener des conversations fluides.',\n",
              "  \"• Interrogation de données tabulaires : LangChain permet d'interroger des données stockées dans des formats tabulaires tels que des bases de données SQL ou des fichiers CSV. Il facilite l'extraction\",\n",
              "  \"l'extraction d'informations spécifiques et la manipulation des données tabulaires.\",\n",
              "  '• Interaction avec des API : LangChain peut être utilisé pour interagir avec des API externes. Il peut envoyer des requêtes, traiter les réponses et intégrer les résultats dans les applications',\n",
              "  'les applications basées sur LangChain.',\n",
              "  '• Extraction : LangChain peut extraire des informations structurées à partir de textes non structurés. Il peut identifier des entités, des relations et des concepts clés dans le texte pour alimenter',\n",
              "  \"pour alimenter d'autres processus ou analyses.\",\n",
              "  '• Résumé : LangChain peut résumer des documents plus longs en générant des résumés concis et informatifs. Il peut extraire les points clés et les informations essentielles pour faciliter la',\n",
              "  'pour faciliter la compréhension et la prise de décision.',\n",
              "  '• Évaluation : LangChain peut être utilisé pour évaluer des modèles génératifs en utilisant des modèles de langage. Il peut mesurer la qualité des réponses générées, la cohérence du langage et',\n",
              "  \"du langage et d'autres métriques d'évaluation.\",\n",
              "  '3. Sources de données',\n",
              "  \"• Bases de données SQL : LangChain permet d'interagir avec des bases de données SQL en utilisant le langage naturel. Il facilite la création de requêtes SQL, l'interrogation de bases de données SQL\",\n",
              "  \"de données SQL et l'interaction avec des bases de données SQL à l'aide d'agents.\",\n",
              "  \"• Ensembles de données Power BI : LangChain offre des outils pour interagir avec des ensembles de données Power BI. Il permet de décrire des tables, d'exécuter des requêtes et d'ajouter des exemples\",\n",
              "  'des exemples spécifiques pour les ensembles de données Power BI.',\n",
              "  \"• Objets JSON : LangChain fournit des utilitaires pour travailler avec des objets JSON. Par exemple, il permet de convertir un objet JSON en une table Markdown à l'aide de la fonction json_to_md.\",\n",
              "  '• Données tabulaires : LangChain permet de charger des données tabulaires à partir de différentes sources telles que des fichiers CSV ou des DataFrames Pandas. Cela facilite le travail avec des',\n",
              "  'le travail avec des données structurées dans les applications basées sur LangChain.',\n",
              "  '4. Bases de données vectorielles',\n",
              "  \"• Chroma : Chroma est une base de données vectorielle gratuite et open-source qui s'exécute sur votre machine locale. Elle permet de stocker des données intégrées et d'effectuer des recherches\",\n",
              "  'des recherches vectorielles.',\n",
              "  '• FAISS : FAISS (Facebook AI Similarity Search) est une base de données vectorielle qui utilise la bibliothèque Facebook AI Similarity Search. Elle offre des capacités de recherche de similarité',\n",
              "  'de similarité efficaces pour les données vectorielles à grande échelle.',\n",
              "  '• LanceDB : LanceDB est une base de données vectorielle open-source basée sur le format de données Lance. Elle offre des fonctionnalités de stockage et de requête de données vectorielles.',\n",
              "  '• Weaviate : Weaviate est une base de données vectorielle open-source avec des capacités de recherche avancées. Elle permet de stocker et de rechercher des données vectorielles.',\n",
              "  '5. Intégration avec Databricks',\n",
              "  \"• Connecteur Databricks pour la chaîne SQLDatabase : LangChain permet d'interroger des données sur Databricks via une chaîne SQLDatabase. Cela facilite l'accès aux données sur Databricks à partir\",\n",
              "  \"Databricks à partir d'applications basées sur LangChain.\",\n",
              "  '• Intégration Databricks MLflow : LangChain peut être utilisé avec MLflow pour le suivi et le déploiement des applications LangChain. Cela permet de gérer et de surveiller les modèles de langage',\n",
              "  'modèles de langage développés avec LangChain.',\n",
              "  \"• Databricks en tant que fournisseur LLM : LangChain permet de déployer des modèles de langage ajustés sur Databricks. Cela facilite l'utilisation de grands modèles de langage dans des environnements\",\n",
              "  'des environnements Databricks.',\n",
              "  \"• Modèles externes Databricks : LangChain facilite l'utilisation de modèles de langage externes dans des environnements Databricks. Cela permet d'intégrer des modèles de langage pré-entraînés dans\",\n",
              "  'pré-entraînés dans des applications basées sur LangChain.',\n",
              "  \"SQL à l'aide d'agents.\",\n",
              "  \"• Modèles : Les modèles sont des composants clés de LangChain qui permettent d'utiliser différents\",\n",
              "  'différents types de modèles de langage, tels que GPT-3, BERT, ou encore T5. Ces modèles peuvent',\n",
              "  'Ces modèles peuvent être utilisés pour générer du texte, répondre à des questions, ou effectuer',\n",
              "  \"ou effectuer d'autres tâches liées au langage naturel.\",\n",
              "  '• Prompts : Les prompts sont des instructions ou des exemples donnés aux modèles de langage pour',\n",
              "  'de langage pour les guider dans leur génération de texte. Ils peuvent être utilisés pour spécifier',\n",
              "  'pour spécifier le contexte, poser des questions ou fournir des indications supplémentaires.',\n",
              "  \"• Mémoire : La mémoire permet de stocker des informations entre les appels d'une chaîne ou d'un\",\n",
              "  \"chaîne ou d'un agent. Elle peut être utilisée pour conserver des états, des variables ou des\",\n",
              "  \"variables ou des résultats intermédiaires lors de l'exécution d'une séquence d'appels.\",\n",
              "  '• Indexes : Les indexes permettent de combiner des modèles de langage avec vos propres données',\n",
              "  \"vos propres données textuelles. Ils facilitent la recherche et l'accès aux informations dans les\",\n",
              "  'dans les données indexées.',\n",
              "  \"• Chaînes : Les chaînes sont des séquences d'appels à des modèles de langage ou à d'autres\",\n",
              "  \"ou à d'autres utilitaires. Elles permettent de créer des flux de travail complexes en enchaînant\",\n",
              "  'en enchaînant différentes étapes de traitement du langage naturel.',\n",
              "  \"• Agents : Les agents permettent d'utiliser des modèles de langage comme moteur de raisonnement en\",\n",
              "  'de raisonnement en prenant des décisions et en effectuant des actions en fonction des instructions',\n",
              "  \"des instructions et des données d'entrée. Ils peuvent être utilisés pour créer des assistants\",\n",
              "  'des assistants virtuels ou des chatbots interactifs.',\n",
              "  \"2. Cas d'utilisation\",\n",
              "  \"• Assistants personnels : Les applications d'assistants personnels utilisent LangChain pour prendre\",\n",
              "  'pour prendre des actions, se souvenir des interactions et avoir des connaissances sur les données',\n",
              "  \"sur les données de l'utilisateur. Ils peuvent répondre aux questions, effectuer des tâches\",\n",
              "  'des tâches spécifiques et fournir des recommandations personnalisées.',\n",
              "  '• Réponse aux questions : LangChain peut être utilisé pour répondre aux questions en utilisant des',\n",
              "  'en utilisant des documents spécifiques. Il peut extraire les informations pertinentes des documents',\n",
              "  'des documents et générer des réponses précises.',\n",
              "  '• Chatbots : Les chatbots utilisent LangChain pour interagir avec les utilisateurs en langage',\n",
              "  'en langage naturel. Ils peuvent comprendre les questions, fournir des réponses pertinentes et mener',\n",
              "  'et mener des conversations fluides.',\n",
              "  \"• Interrogation de données tabulaires : LangChain permet d'interroger des données stockées dans des\",\n",
              "  'stockées dans des formats tabulaires tels que des bases de données SQL ou des fichiers CSV. Il',\n",
              "  \"fichiers CSV. Il facilite l'extraction d'informations spécifiques et la manipulation des données\",\n",
              "  'des données tabulaires.',\n",
              "  '• Interaction avec des API : LangChain peut être utilisé pour interagir avec des API externes. Il',\n",
              "  'API externes. Il peut envoyer des requêtes, traiter les réponses et intégrer les résultats dans les',\n",
              "  'résultats dans les applications basées sur LangChain.',\n",
              "  '• Extraction : LangChain peut extraire des informations structurées à partir de textes non',\n",
              "  'de textes non structurés. Il peut identifier des entités, des relations et des concepts clés dans',\n",
              "  \"concepts clés dans le texte pour alimenter d'autres processus ou analyses.\",\n",
              "  '• Résumé : LangChain peut résumer des documents plus longs en générant des résumés concis et',\n",
              "  'résumés concis et informatifs. Il peut extraire les points clés et les informations essentielles',\n",
              "  'essentielles pour faciliter la compréhension et la prise de décision.',\n",
              "  '• Évaluation : LangChain peut être utilisé pour évaluer des modèles génératifs en utilisant des',\n",
              "  'en utilisant des modèles de langage. Il peut mesurer la qualité des réponses générées, la cohérence',\n",
              "  \"la cohérence du langage et d'autres métriques d'évaluation.\",\n",
              "  '3. Sources de données',\n",
              "  \"• Bases de données SQL : LangChain permet d'interagir avec des bases de données SQL en utilisant le\",\n",
              "  \"SQL en utilisant le langage naturel. Il facilite la création de requêtes SQL, l'interrogation de\",\n",
              "  \"l'interrogation de bases de données SQL et l'interaction avec des bases de données SQL à l'aide\",\n",
              "  \"SQL à l'aide d'agents.\",\n",
              "  '• Ensembles de données Power BI : LangChain offre des outils pour interagir avec des ensembles de',\n",
              "  \"des ensembles de données Power BI. Il permet de décrire des tables, d'exécuter des requêtes et\",\n",
              "  \"des requêtes et d'ajouter des exemples spécifiques pour les ensembles de données Power BI.\",\n",
              "  '• Objets JSON : LangChain fournit des utilitaires pour travailler avec des objets JSON. Par',\n",
              "  \"objets JSON. Par exemple, il permet de convertir un objet JSON en une table Markdown à l'aide de la\",\n",
              "  \"à l'aide de la fonction json_to_md.\",\n",
              "  '• Données tabulaires : LangChain permet de charger des données tabulaires à partir de différentes',\n",
              "  'de différentes sources telles que des fichiers CSV ou des DataFrames Pandas. Cela facilite le',\n",
              "  'Cela facilite le travail avec des données structurées dans les applications basées sur LangChain.',\n",
              "  '4. Bases de données vectorielles',\n",
              "  \"• Chroma : Chroma est une base de données vectorielle gratuite et open-source qui s'exécute sur\",\n",
              "  \"qui s'exécute sur votre machine locale. Elle permet de stocker des données intégrées et d'effectuer\",\n",
              "  \"et d'effectuer des recherches vectorielles.\",\n",
              "  '• FAISS : FAISS (Facebook AI Similarity Search) est une base de données vectorielle qui utilise la',\n",
              "  'qui utilise la bibliothèque Facebook AI Similarity Search. Elle offre des capacités de recherche de',\n",
              "  'de recherche de similarité efficaces pour les données vectorielles à grande échelle.',\n",
              "  '• LanceDB : LanceDB est une base de données vectorielle open-source basée sur le format de données',\n",
              "  'format de données Lance. Elle offre des fonctionnalités de stockage et de requête de données',\n",
              "  'requête de données vectorielles.',\n",
              "  '• Weaviate : Weaviate est une base de données vectorielle open-source avec des capacités de',\n",
              "  'des capacités de recherche avancées. Elle permet de stocker et de rechercher des données',\n",
              "  'des données vectorielles.',\n",
              "  '5. Intégration avec Databricks',\n",
              "  \"• Connecteur Databricks pour la chaîne SQLDatabase : LangChain permet d'interroger des données sur\",\n",
              "  \"des données sur Databricks via une chaîne SQLDatabase. Cela facilite l'accès aux données sur\",\n",
              "  \"aux données sur Databricks à partir d'applications basées sur LangChain.\",\n",
              "  '• Intégration Databricks MLflow : LangChain peut être utilisé avec MLflow pour le suivi et le',\n",
              "  'pour le suivi et le déploiement des applications LangChain. Cela permet de gérer et de surveiller',\n",
              "  'et de surveiller les modèles de langage développés avec LangChain.',\n",
              "  '• Databricks en tant que fournisseur LLM : LangChain permet de déployer des modèles de langage',\n",
              "  \"modèles de langage ajustés sur Databricks. Cela facilite l'utilisation de grands modèles de langage\",\n",
              "  'modèles de langage dans des environnements Databricks.',\n",
              "  \"• Modèles externes Databricks : LangChain facilite l'utilisation de modèles de langage externes\",\n",
              "  \"de langage externes dans des environnements Databricks. Cela permet d'intégrer des modèles de\",\n",
              "  'des modèles de langage pré-entraînés dans des applications basées sur LangChain.',\n",
              "  '1. Modules',\n",
              "  \"• Modèles : Les modèles sont des composants clés de LangChain qui permettent d'utiliser différents types de modèles de langage, tels que GPT-3, BERT, ou encore T5. Ces modèles peuvent être utilisés pour générer du texte, répondre à des questions, ou effectuer d'autres tâches liées au langage naturel.\\n• Prompts : Les prompts sont des instructions ou des exemples donnés aux modèles de langage pour les guider dans leur génération de texte. Ils peuvent être utilisés pour spécifier le contexte, poser des questions ou fournir des indications supplémentaires.\\n• Mémoire : La mémoire permet de stocker des informations entre les appels d'une chaîne ou d'un agent. Elle peut être utilisée pour conserver des états, des variables ou des résultats intermédiaires lors de l'exécution d'une séquence d'appels.\\n• Indexes : Les indexes permettent de combiner des modèles de langage avec vos propres données textuelles. Ils facilitent la recherche et l'accès aux informations dans les données indexées.\",\n",
              "  \"• Chaînes : Les chaînes sont des séquences d'appels à des modèles de langage ou à d'autres utilitaires. Elles permettent de créer des flux de travail complexes en enchaînant différentes étapes de traitement du langage naturel.\\n• Agents : Les agents permettent d'utiliser des modèles de langage comme moteur de raisonnement en prenant des décisions et en effectuant des actions en fonction des instructions et des données d'entrée. Ils peuvent être utilisés pour créer des assistants virtuels ou des chatbots interactifs.\",\n",
              "  \"2. Cas d'utilisation\",\n",
              "  \"• Assistants personnels : Les applications d'assistants personnels utilisent LangChain pour prendre des actions, se souvenir des interactions et avoir des connaissances sur les données de l'utilisateur. Ils peuvent répondre aux questions, effectuer des tâches spécifiques et fournir des recommandations personnalisées.\\n• Réponse aux questions : LangChain peut être utilisé pour répondre aux questions en utilisant des documents spécifiques. Il peut extraire les informations pertinentes des documents et générer des réponses précises.\\n• Chatbots : Les chatbots utilisent LangChain pour interagir avec les utilisateurs en langage naturel. Ils peuvent comprendre les questions, fournir des réponses pertinentes et mener des conversations fluides.\",\n",
              "  \"• Interrogation de données tabulaires : LangChain permet d'interroger des données stockées dans des formats tabulaires tels que des bases de données SQL ou des fichiers CSV. Il facilite l'extraction d'informations spécifiques et la manipulation des données tabulaires.\\n• Interaction avec des API : LangChain peut être utilisé pour interagir avec des API externes. Il peut envoyer des requêtes, traiter les réponses et intégrer les résultats dans les applications basées sur LangChain.\\n• Extraction : LangChain peut extraire des informations structurées à partir de textes non structurés. Il peut identifier des entités, des relations et des concepts clés dans le texte pour alimenter d'autres processus ou analyses.\\n• Résumé : LangChain peut résumer des documents plus longs en générant des résumés concis et informatifs. Il peut extraire les points clés et les informations essentielles pour faciliter la compréhension et la prise de décision.\",\n",
              "  \"• Évaluation : LangChain peut être utilisé pour évaluer des modèles génératifs en utilisant des modèles de langage. Il peut mesurer la qualité des réponses générées, la cohérence du langage et d'autres métriques d'évaluation.\",\n",
              "  \"3. Sources de données\\n\\n• Bases de données SQL : LangChain permet d'interagir avec des bases de données SQL en utilisant le langage naturel. Il facilite la création de requêtes SQL, l'interrogation de bases de données SQL et l'interaction avec des bases de données SQL à l'aide d'agents.\\n• Ensembles de données Power BI : LangChain offre des outils pour interagir avec des ensembles de données Power BI. Il permet de décrire des tables, d'exécuter des requêtes et d'ajouter des exemples spécifiques pour les ensembles de données Power BI.\\n• Objets JSON : LangChain fournit des utilitaires pour travailler avec des objets JSON. Par exemple, il permet de convertir un objet JSON en une table Markdown à l'aide de la fonction json_to_md.\\n• Données tabulaires : LangChain permet de charger des données tabulaires à partir de différentes sources telles que des fichiers CSV ou des DataFrames Pandas. Cela facilite le travail avec des données structurées dans les applications basées sur LangChain.\",\n",
              "  \"4. Bases de données vectorielles\\n\\n• Chroma : Chroma est une base de données vectorielle gratuite et open-source qui s'exécute sur votre machine locale. Elle permet de stocker des données intégrées et d'effectuer des recherches vectorielles.\\n• FAISS : FAISS (Facebook AI Similarity Search) est une base de données vectorielle qui utilise la bibliothèque Facebook AI Similarity Search. Elle offre des capacités de recherche de similarité efficaces pour les données vectorielles à grande échelle.\\n• LanceDB : LanceDB est une base de données vectorielle open-source basée sur le format de données Lance. Elle offre des fonctionnalités de stockage et de requête de données vectorielles.\\n• Weaviate : Weaviate est une base de données vectorielle open-source avec des capacités de recherche avancées. Elle permet de stocker et de rechercher des données vectorielles.\\n\\n5. Intégration avec Databricks\",\n",
              "  \"• Connecteur Databricks pour la chaîne SQLDatabase : LangChain permet d'interroger des données sur Databricks via une chaîne SQLDatabase. Cela facilite l'accès aux données sur Databricks à partir d'applications basées sur LangChain.\\n• Intégration Databricks MLflow : LangChain peut être utilisé avec MLflow pour le suivi et le déploiement des applications LangChain. Cela permet de gérer et de surveiller les modèles de langage développés avec LangChain.\\n• Databricks en tant que fournisseur LLM : LangChain permet de déployer des modèles de langage ajustés sur Databricks. Cela facilite l'utilisation de grands modèles de langage dans des environnements Databricks.\\n• Modèles externes Databricks : LangChain facilite l'utilisation de modèles de langage externes dans des environnements Databricks. Cela permet d'intégrer des modèles de langage pré-entraînés dans des applications basées sur LangChain.\"],\n",
              " 'uris': None,\n",
              " 'data': None}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Obtenir tous les documents d'une collection\n",
        "\n",
        "collection = chroma_db.get()\n",
        "\n",
        "collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "708f8d50",
      "metadata": {
        "id": "708f8d50",
        "outputId": "96c82a0c-c41b-4602-d107-58b25c4619f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': ['0d6d65f5-a35b-11ee-9387-c17a6171887f',\n",
              "  '37ebbc89-a340-11ee-b46f-c17a6171887f'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [{'source': './langchain.txt',\n",
              "   'start_index': 0,\n",
              "   'tag': 'agents'},\n",
              "  {'source': './langchain.txt', 'start_index': 0, 'tag': 'agents'}],\n",
              " 'documents': [\"• Mémoire : La mémoire permet de stocker des informations entre les appels d'une chaîne ou d'un agent. Elle peut être utilisée pour conserver des états, des variables ou des résultats intermédiaires\",\n",
              "  \"SQL à l'aide d'agents.\"],\n",
              " 'uris': None,\n",
              " 'data': None}"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mettre à jour une collection\n",
        "\n",
        "# assigning custom tag metadata to first document\n",
        "similar_docs[0].metadata = {\n",
        "    \"tag\": \"agents\"\n",
        "}\n",
        "\n",
        "# updating the vector store\n",
        "chroma_db.update_document(\n",
        "    document=similar_docs[0],\n",
        "    document_id=collection['ids'][0]\n",
        ")\n",
        "\n",
        "# using the where parameter to filter the collection\n",
        "collection = chroma_db.get(where={\"tag\" : \"agents\"})\n",
        "collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "913a78dc",
      "metadata": {
        "id": "913a78dc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Pytorch GPU (Python 3.10)",
      "language": "python",
      "name": "pytorch_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}